{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://www.kaggle.com/c/allstate-claims-severity\n",
    "\n",
    "# Discussions\n",
    "- https://habrahabr.ru/post/318518/\n",
    "- https://www.youtube.com/watch?v=p7ArDjMImiI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import RegressorMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ds_tools/dstools/ml/transformers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitri/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run ds_tools/dstools/ml/xgboost_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ds_tools/dstools/h2o/sklearn_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetTransfRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_est, transf_to, transf_from):\n",
    "        self.base_est = base_est\n",
    "        self.transf_to = transf_to\n",
    "        self.transf_from = transf_from\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_est.fit(X, self.transf_to(y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.transf_from(self.base_est.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.average(np.abs(y_pred - y_true), axis=0)\n",
    "\n",
    "\n",
    "def mape_evalerror_exp(preds, dtrain):\n",
    "    res = np.average(np.abs(np.exp(preds) - np.exp(dtrain.get_label())), axis=0)\n",
    "    return 'mae', res\n",
    "\n",
    "\n",
    "def mape_evalerror(preds, dtrain):\n",
    "    return 'mape', mape(dtrain.get_label(), preds)\n",
    "\n",
    "\n",
    "def ybin(y):\n",
    "    return (y.astype(np.float64) / np.max(y) * 10).astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_test(est):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='id')\n",
    "\n",
    "    features = df.drop('loss', axis=1)\n",
    "    target = df.loss.values\n",
    "\n",
    "    if type(est) is tuple:\n",
    "        transform, estimator = est\n",
    "        features_t = transform.fit_transform(features, target)\n",
    "    else:\n",
    "        estimator = est\n",
    "        features_t = features\n",
    "\n",
    "    cv = KFold(3, shuffle=True)\n",
    "\n",
    "    scores = cross_val_score(estimator, X=features_t, y=target, scoring=make_scorer(mape), cv=cv)\n",
    "    print('mean: {mean}, std: {std}'.format(mean=scores.mean(), std=scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_vs_true(est, path):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='id')\n",
    "    features = df.drop('loss', axis=1)\n",
    "    target = df.loss.values\n",
    "\n",
    "    transform, estimator = est\n",
    "    pl = make_pipeline(transform, estimator)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, train_size=0.9, random_state=123)\n",
    "    y_pred = pl.fit(x_train, y_train).predict(x_test)\n",
    "    pd.DataFrame({'pred': y_pred, 'true': y_test}).to_csv(path, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": 0.1,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"eval_func\": mape_evalerror_exp,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 4,\n",
    "    \"num_rounds\": 10000,\n",
    "    \"num_es_rounds\": 120,\n",
    "    \"es_share\": .1,\n",
    "    \"ybin\": ybin,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params2 = {\n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"eta\": 0.05,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"eval_func\": mape_evalerror,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 4,\n",
    "    \"num_rounds\": 1000,\n",
    "    \"num_es_rounds\": None,\n",
    "    \"es_share\": .1,\n",
    "    \"ybin\": ybin,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def high_cardinality_zeroing(df, min_entries=50, substitute='zeroed'):\n",
    "    dfc = df.copy()\n",
    "    for col in dfc.select_dtypes(include=['object']):\n",
    "        vc = dfc[col].value_counts()\n",
    "        dfc.ix[~dfc[col].isin(vc[vc >= min_entries].index), col] = substitute\n",
    "    return dfc\n",
    "\n",
    "hcz_transf = FunctionTransformer(high_cardinality_zeroing, validate=False)\n",
    "\n",
    "df2dict = FunctionTransformer(\n",
    "    lambda x: x.to_dict(orient='records'), validate=False)\n",
    "\n",
    "transf = make_pipeline(\n",
    "    hcz_transf,\n",
    "    df2dict,\n",
    "    DictVectorizer(sparse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf2 = CountEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf3 = TargetMeanEncoder(reg_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 1155.38459245, std: 1.66143441458\n",
    "# cv execution time: 2173.90924597 sec\n",
    "est1 = transf, TargetTransfRegressor(XGBoostRegressor(**xgb_params), np.log, np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 1155.41551477, std: 1.95293210141\n",
    "# cv execution time: 341.660254955 sec\n",
    "est2 = transf2, TargetTransfRegressor(XGBoostRegressor(**xgb_params), np.log, np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 1193.08011539, std: 3.45706005863\n",
    "# cv execution time: 382.747917891 sec\n",
    "est3 = transf2, XGBoostRegressor(**xgb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o_gbm_params = {\n",
    "    'model_id': 'kaggle_allstate_gbm',\n",
    "    'distribution': 'laplace',\n",
    "    'ntrees': 1000,\n",
    "    'learn_rate': .1,\n",
    "    'max_depth': 4,\n",
    "    'sample_rate': .7,\n",
    "    'col_sample_rate_per_tree': .5\n",
    "}\n",
    "\n",
    "# mean: 1169.26570704, std: 8.97162412921\n",
    "# cv execution time: 885.310971975 sec\n",
    "est4 = H2ODecorator('gbm', h2o_gbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o_xgb_params = {\n",
    "    'model_id': 'kaggle_allstate_xgb',\n",
    "    'distribution': 'poisson',\n",
    "    'ntrees': 1000,\n",
    "    'learn_rate': .1,\n",
    "    'max_depth': 4,\n",
    "    'sample_rate': .7,\n",
    "    'col_sample_rate_per_tree': .5\n",
    "}\n",
    "\n",
    "# mean: 3036.83769373, std: 12.8838933342\n",
    "# cv execution time: 322.227102995 sec\n",
    "est5 = H2ODecorator('xgb', h2o_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 1154.64991991, std: 4.90194453789\n",
    "# cv execution time: 373.575634003 sec\n",
    "est6 = transf2, TargetTransfRegressor(XGBoostRegressor(**xgb_params), np.log, np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
